{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb98cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe031e27",
   "metadata": {},
   "source": [
    "Define classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e22637",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CyberbullyingPreprocessor:\n",
    "    \"\"\"\n",
    "    Preprocessor class to clean data\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def clean(self, text):\n",
    "        \"\"\"Lowercase and remove URLs, @mentions, hashtags, and punctuation.\"\"\"\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"http\\S+|@\\w+|#\\w+\", \"\", text)  # Remove URLs, mentions, hashtags\n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text)  # Remove punctuation\n",
    "        return text\n",
    "\n",
    "class FeedforwardNeuralNet:\n",
    "    def __init__(self, input_size, hidden_size=64, learning_rate: float=0.01, epochs=100):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = 1  # binary classification\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "\n",
    "        # Initialize weights and biases with small random values\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size) * 0.01\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size) * 0.01\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, a):\n",
    "        return a * (1 - a)\n",
    "\n",
    "    def relu(self, z):\n",
    "        # ReLu function: g(x) = max(0, x)\n",
    "        return np.maximum(0, z)\n",
    "\n",
    "    def relu_derivative(self, z):\n",
    "        # RELU derivative function is: for x > 0 = 1, for x < 0 = 0 \n",
    "        return (z > 0).astype(float)\n",
    "\n",
    "    def binary_cross_entropy(self, y_true, y_pred):\n",
    "        epsilon = 1e-9  # small value to avoid log(0)\n",
    "        return -np.mean(y_true * np.log(y_pred + epsilon) + (1 - y_true) * np.log(1 - y_pred + epsilon))\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Forward pass: compute predictions.\"\"\"\n",
    "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.A1 = self.relu(self.Z1)\n",
    "\n",
    "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
    "        self.A2 = self.sigmoid(self.Z2)\n",
    "\n",
    "        return self.A2  # Probabilities between 0 and 1\n",
    "\n",
    "    def backward(self, X, y_true, y_pred):\n",
    "        \"\"\"Backward pass: compute gradients and update weights.\"\"\"\n",
    "        m = X.shape[0]  # number of samples\n",
    "\n",
    "        # Output layer gradients\n",
    "        dZ2 = y_pred - y_true.reshape(-1, 1)\n",
    "        dW2 = np.dot(self.A1.T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Hidden layer gradients\n",
    "        dA1 = np.dot(dZ2, self.W2.T)\n",
    "        dZ1 = dA1 * self.relu_derivative(self.Z1)\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Gradient descent updates\n",
    "        self.W2 -= self.lr * dW2\n",
    "        self.b2 -= self.lr * db2\n",
    "        self.W1 -= self.lr * dW1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\"Train the neural network using gradient descent.\"\"\"\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.forward(X)\n",
    "            loss = self.binary_cross_entropy(y, y_pred)\n",
    "            self.backward(X, y, y_pred)\n",
    "\n",
    "            # if epoch % 10 == 0 or epoch == self.epochs - 1:\n",
    "            #     print(f\"Epoch {epoch} | Loss: {loss:.4f}\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict binary labels based on 0.5 threshold.\"\"\"\n",
    "        probs = self.forward(X)\n",
    "        return (probs >= 0.5).astype(int)\n",
    "\n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Compute accuracy.\"\"\"\n",
    "        preds = self.predict(X)\n",
    "        accuracy = np.mean(preds.flatten() == y)\n",
    "        return accuracy\n",
    "    \n",
    "# Load your processed CSV from the previous script\n",
    "filepath = \"../data/preprocessing/output/\"\n",
    "filename = \"train_subset_clean.csv\"\n",
    "# filename = \"clean_data.csv\"\n",
    "df = pd.read_csv(filepath + filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a17ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text data\n",
    "preprocessor = CyberbullyingPreprocessor()\n",
    "df['clean_comment'] = df['comment'].astype(str).apply(preprocessor.clean)\n",
    "X = df['clean_comment'].astype(str)\n",
    "\n",
    "# Convert cleaned text to bag-of-words vectors\n",
    "vectorizer = CountVectorizer(max_features=1000)\n",
    "X = vectorizer.fit_transform(df['clean_comment']).toarray()\n",
    "\n",
    "# Convert DataFrame to 1D NumPy array\n",
    "y = df[['toxic', 'threat', 'insult', 'discrimination']].sum(axis=1)\n",
    "y = (y > 0).astype(int).values  # convert to binary and flatten to np.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dd81ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.87      0.79        92\n",
      "           1       0.82      0.64      0.72        87\n",
      "\n",
      "    accuracy                           0.76       179\n",
      "   macro avg       0.77      0.76      0.76       179\n",
      "weighted avg       0.77      0.76      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# train and split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# train the feedforward Neural network\n",
    "model = FeedforwardNeuralNet(input_size=X.shape[1], hidden_size=32, learning_rate=0.1, epochs=100)\n",
    "model.train(X_train, y_train)\n",
    "\n",
    "# evaluate the model and generate accuracy scores\n",
    "accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# display classification report\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MSE_446",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
